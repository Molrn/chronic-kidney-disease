{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2c452b8",
   "metadata": {},
   "source": [
    "# Feature selection Techniques\n",
    "\n",
    "This notebook consists in detailing the most appropriate features according to different feature selection techniques\n",
    "\n",
    "## Filter Methods \n",
    "\n",
    "Calculate the correlations between the features and target attributes\n",
    "\n",
    "### Divide of features into two categories \n",
    "    - Categorical features (Nominal): albumin - sugar - red_blood_cells  - pus_cell  - pus_cell_clumps  - bacteria  - hypertension  - diabetes_mellitus  - coronary_artery_disease  - appetite  - peda_edema  - aanemia  \n",
    " \n",
    "    - Numearical features (Ordinal) : age  - blood_pressure  - specific_gravity    - blood_glucose_random  - blood_urea  - serum_creatinine  - sodium  - potassium  - hemoglobin  - packed_cell_volume  - white_blood_cell_count  - red_blood_cell_count\n",
    "    \n",
    "\n",
    "To divide them, we checked the values in the dataset of each feature and the meaning behind it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe30ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(r'Data/clean_dataset.csv')\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598461e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=['albumin' ,\n",
    "              'sugar' ,\n",
    "              'red_blood_cells'  ,\n",
    "              'pus_cell'  ,\n",
    "              'pus_cell_clumps'  ,\n",
    "              'bacteria'  ,\n",
    "              'hypertension'   ,\n",
    "              'diabetes_mellitus'  ,\n",
    "              'coronary_artery_disease'  ,\n",
    "              'appetite'   ,\n",
    "              'peda_edema'  ,\n",
    "              'aanemia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ac6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=['age'  ,\n",
    "              'blood_pressure'  ,\n",
    "              'specific_gravity'    ,\n",
    "              'blood_glucose_random'  ,\n",
    "              'blood_urea'  ,\n",
    "              'serum_creatinine'  ,\n",
    "              'sodium'  ,\n",
    "              'potassium'  ,\n",
    "              'hemoglobin'  ,\n",
    "              'packed_cell_volume',\n",
    "              'white_blood_cell_count'  ,\n",
    "              'red_blood_cell_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((cat_features, num_features), axis=0)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_features)+len(cat_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56f85f7f",
   "metadata": {},
   "source": [
    "### Variance test\n",
    "The objective of this test is to determine the constants in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold = 0)\n",
    "selector.fit(clean_df)\n",
    "\n",
    "print(selector.get_support())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d4de5ee",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- There is no constant in the project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "785974af",
   "metadata": {},
   "source": [
    "### Correlation between numerical features (Pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7add8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=clean_df[num_features].corr()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strongly  correlated feature are 0.7 and more so we will select the thershold = 0.7\n",
    "correlation_threshold=0.7\n",
    "\n",
    "mask = (abs(corr) > correlation_threshold) & (abs(corr) <1)\n",
    "strongly_correlated_features = corr[mask].stack().dropna().reset_index()\n",
    "\n",
    "selected_features = set(strongly_correlated_features['level_0']).union(strongly_correlated_features['level_1'])\n",
    "\n",
    "strongly_correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f918f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximizeCorrelation(corr,selected_features):\n",
    "    max=0\n",
    "    best_feature_tokeep=''\n",
    "    for feature in selected_features:\n",
    "        s= corr[corr['level_0']==feature][0].sum()\n",
    "        if s > max:\n",
    "            max=s\n",
    "            best_feature_tokeep=feature\n",
    "    return [best_feature_tokeep,max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7778a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximizeCorrelation(strongly_correlated_features,selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.ceil(math.factorial(len(selected_features)) /4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ca1b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Check the resultat by ploting some graph\n",
    "# for the different features (hemoglobin , packed_cell_volume ,red_blood_cell_count) are correlated\n",
    "# (hemoglobin , potassium , age) that are not correlated \n",
    "\n",
    "features=['packed_cell_volume','red_blood_cell_count','potassium','age']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15, 7))\n",
    "plotnumber=1\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "    ax = plt.subplot(2, 2, plotnumber)\n",
    "    sns.scatterplot(data=clean_df, x='hemoglobin', y=feature)\n",
    "    plotnumber+=1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Can confirm the resultats by the graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cc5b5e",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "- We can delete 'packed_cell_volume' and 'red_blood_cell_count' features and keep the 'hemoglobin' feature, as it maximizes the desired outcome.\n",
    "- We need to first check the correlation of these features with the target variable before deciding whether to delete them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de4659c2",
   "metadata": {},
   "source": [
    "### Correlation between numerical features and  the target (categorical variable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d48cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=[]\n",
    "for feature in num_features:\n",
    "    pb_corr, pb_p_value = stats.pointbiserialr(   # Used between a binary categorical variable and numerical one\n",
    "        clean_df[feature],\n",
    "        clean_df[target])\n",
    "    corr.append([feature,abs(pb_corr)])\n",
    "corr=pd.DataFrame(corr,columns=['num_feature','correlation with the target'])\n",
    "\n",
    "corr.sort_values(by='correlation with the target'  ,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a205d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the resultat by ploting some graphs\n",
    "# for the different features (hemoglobin , packed_cell_volume ,specific_gravity) high correlated with the target\n",
    "# (white_blood_cell_count , potassium , age) that are low correlated with the target \n",
    "features=['hemoglobin','specific_gravity','packed_cell_volume','potassium','white_blood_cell_count','age']\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20, 15))\n",
    "plotnumber=1\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "    ax = plt.subplot(3, 2, plotnumber)\n",
    "    sns.boxplot(x=target, y=feature, data=clean_df)\n",
    "    plotnumber+=1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Can confirm the resultats by the graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "243570d8",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The most important features are : hemoglobin, specific_gravity ,packed_cell_volume ,red_blood_cell_count\n",
    "- feature to delete : potassium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f746d21",
   "metadata": {},
   "source": [
    "### Correlation between categorical features and the categorical target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac89713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carmerV(clean_df,col1,col2):\n",
    "    contingency_table = pd.crosstab(clean_df[col1], clean_df[col2])\n",
    "    \n",
    "\n",
    "    # Calculate CramÃ©r's V\n",
    "    chi2 = stats.chi2_contingency(contingency_table)[0]\n",
    "    n = contingency_table.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = contingency_table.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "    rcorr = r - ((r - 1)**2) / (n - 1)\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1)\n",
    "    V = np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=[]\n",
    "for col in cat_features:\n",
    "    V=carmerV(clean_df,col,target)\n",
    "    corr.append([col,V])\n",
    "    \n",
    "\n",
    "corr=pd.DataFrame(corr,columns=['cat_feature','correlation with the target'])\n",
    "\n",
    "corr.sort_values(by='correlation with the target'  ,ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf04611e",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The most important features are : albumin, hypertension ,diabetes_mellitus ,red_blood_cells\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff626b79",
   "metadata": {},
   "source": [
    "### Correlation between categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7448b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows= []\n",
    "\n",
    "for f1 in cat_features:\n",
    "    col = []\n",
    "    for f2 in cat_features:\n",
    "        v=carmerV(clean_df,f1,f2)\n",
    "        col.append(v)\n",
    "    rows.append(col)\n",
    "    \n",
    "cramers_results = np.array(rows)\n",
    "corr_cat_features = pd.DataFrame(cramers_results, columns = cat_features, index =cat_features)\n",
    "corr_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_threshold=0.7\n",
    "mask = (corr_cat_features > correlation_threshold) & (corr_cat_features <0.97)\n",
    "corr_cat_features[mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e717502",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Categorical features are not correlated with each other (have low correlation)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test de correlation entre cat features and num features (utilisation de anova / faut verifier les assumptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b022e22",
   "metadata": {},
   "source": [
    "## Feature importance using tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                                  random_state=0)\n",
    "\n",
    "rf.fit(clean_df[features], clean_df[target])\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfa048",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = feature_importances.argsort()[::-1]\n",
    "sorted_feature_importances = feature_importances[indices]\n",
    "sorted_feature_names = [clean_df.columns[i] for i in indices]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(len(sorted_feature_importances)), sorted_feature_importances)\n",
    "plt.xticks(range(len(sorted_feature_importances)), sorted_feature_names, rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de80f639",
   "metadata": {},
   "source": [
    "## Feature importance using Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(clean_df[features], clean_df[target], random_state=1)\n",
    "my_model = RandomForestClassifier(n_estimators=100,\n",
    "                                  random_state=0).fit(train_X, train_y)\n",
    "\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b77eaadd",
   "metadata": {},
   "source": [
    "## Feature importance using  Coefficients in  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(clean_df[features], clean_df[target])\n",
    "\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Get the absolute feature importance\n",
    "feature_importances = np.abs(coefficients)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(len(sorted_idx)), feature_importances[sorted_idx])\n",
    "plt.xticks(range(len(sorted_idx)), [clean_df[features].columns[i] for i in sorted_idx], rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importances (Logistic Regression)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70828255",
   "metadata": {},
   "source": [
    "## Represent the data in other format and check if it improve the resultat of the machine learning algorthms "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39bbf03a",
   "metadata": {},
   "source": [
    "### PCA representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA (n_components=0.99,whiten=True)\n",
    "\n",
    "pca_data=pca.fit_transform(clean_df)\n",
    "variance_explained =pca.explained_variance_ratio_\n",
    "print('The variance added by each component')\n",
    "print(variance_explained)\n",
    "print('number of PCA is ',len(variance_explained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c68dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance_ratio = np.cumsum(variance_explained)\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Variance Explained by Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = sns.scatterplot(x=pca_data[:, 0], y=pca_data[:, 1], hue=clean_df[target], palette='viridis')\n",
    "\n",
    "# Manually set the legend labels\n",
    "scatter.legend_.set_title('classification')\n",
    "scatter.legend_.texts = ['ckd', 'notckd']\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Scatter Plot with 2 PC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3fc1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# axes instance\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# get colormap from seaborn\n",
    "cmap = ListedColormap(sns.color_palette(\"husl\", 2).as_hex())\n",
    "\n",
    "# plot\n",
    "sc = ax.scatter(pca_data[:, 0], pca_data[:, 1], pca_data[:, 2], s=40, c=clean_df[target], marker='o', cmap=cmap, alpha=1)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Scatter Plot with 3 PC')\n",
    "\n",
    "\n",
    "# legend\n",
    "plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_columns_pc = [f'PC{i}' for i in range(1, len(variance_explained) + 1)]\n",
    "name_columns_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data=pca_data,columns=name_columns_pc)\n",
    "df_pca=pd.concat((df_pca, clean_df[target]), axis=1)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved it to excel file \n",
    "df_pca.to_csv('Data/pca_dataset.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "155a23d4",
   "metadata": {},
   "source": [
    "### LDA representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the LDA model on the training data\n",
    "X_lda=lda.fit_transform(clean_df[features], clean_df[target])\n",
    "\n",
    "X_lda.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a298f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_lda, clean_df[target], c=clean_df[target], cmap='viridis')\n",
    "plt.xlabel('LDA Component')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Scatter Plot of LDA-Transformed Data')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_columns_lda = [f'LDA{i}' for i in range(1, len(lda.explained_variance_ratio_) + 1)]\n",
    "name_columns_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c13bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda = pd.DataFrame(data=X_lda,columns=name_columns_lda)\n",
    "df_lda=pd.concat((df_lda, clean_df[target]), axis=1)\n",
    "df_lda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved it to excel file \n",
    "df_lda.to_csv('Data/lda_dataset.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "743b8be4",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- Corrolation between cat and num feature\n",
    "- Make a conclusion \n",
    "- Use random forest and other algo for feature importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c40e09ff",
   "metadata": {},
   "source": [
    "# RQ:\n",
    "- Can add LDA (the model finds linear combinations of the features that achieve maximum separability between the classes and minimum variance within each class) (done)\n",
    "- PCA as preprocessing step (done)\n",
    "- diplay with the only two PCA and then three PCA (done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
